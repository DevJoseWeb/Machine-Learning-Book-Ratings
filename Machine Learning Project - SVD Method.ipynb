{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "from surprise import Reader, Dataset, SVD, model_selection, accuracy\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_books_users_ratings = pd.read_csv(\"data/clean/reduced_books_users_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_users_ratings = pd.read_csv(\"data/clean/books_users_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>unique_isbn</th>\n",
       "      <th>book_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11676</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11676</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11676</td>\n",
       "      <td>0684867621</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11676</td>\n",
       "      <td>8437606322</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id unique_isbn  book_rating\n",
       "0    11676  038550120X           10\n",
       "1    11676  0671537458            8\n",
       "2    11676  0679776818            8\n",
       "3    11676  0684867621            3\n",
       "4    11676  8437606322            8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_rating = reduced_books_users_ratings[['user_id', 'unique_isbn', 'book_rating']]\n",
    "user_item_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(user_item_rating, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test\n",
    "train_data, test_data = model_selection.train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_factors': [80, 100, 120], 'lr_all': [0.001, 0.005, 0.01], 'reg_all': [0.01, 0.02, 0.04]}\n",
    "\n",
    "# Optimize SVD algorithm for both root mean squared error ('rmse') and mean average error ('mae')\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 13s, sys: 2.91 s, total: 4min 16s\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "# Fit the gridsearch result on the entire dataset\n",
    "%time gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5718280100211657\n",
      "{'n_factors': 80, 'lr_all': 0.005, 'reg_all': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Return the best version of the SVD algorithm\n",
    "model = gs.best_estimator['rmse']\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5693  1.5717  1.5764  1.5748  1.5700  1.5724  0.0028  \n",
      "MAE (testset)     1.2155  1.2088  1.2127  1.2093  1.2119  1.2116  0.0025  \n",
      "Fit time          4.51    4.49    4.54    4.48    4.46    4.50    0.03    \n",
      "Test time         0.15    0.15    0.15    0.16    0.23    0.17    0.03    \n",
      "CPU times: user 24.7 s, sys: 52.1 ms, total: 24.7 s\n",
      "Wall time: 24.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.56927535, 1.57170023, 1.57643769, 1.57480061, 1.56998285]),\n",
       " 'test_mae': array([1.21552353, 1.20875547, 1.21271826, 1.20928167, 1.21190043]),\n",
       " 'fit_time': (4.513628959655762,\n",
       "  4.486056089401245,\n",
       "  4.5405848026275635,\n",
       "  4.477702856063843,\n",
       "  4.4607648849487305),\n",
       " 'test_time': (0.15320396423339844,\n",
       "  0.1505589485168457,\n",
       "  0.14806485176086426,\n",
       "  0.15732812881469727,\n",
       "  0.2307729721069336)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model_selection.cross_validate(model, data, measures=['rmse', 'mae'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD : Test Set\n",
      "RMSE: 1.5875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5875037441944968"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use the new parameters with the training set\n",
    "model = SVD(n_factors=80, lr_all=0.005, reg_all=0.04)\n",
    "model.fit(train_data) # re-fit on only the training data using the best hyperparameters\n",
    "test_pred = model.test(test_data)\n",
    "print(\"SVD : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reading_list(userid, predictions):\n",
    "    \"\"\"\n",
    "    Retrieve full book titles from full 'books_users_ratings' dataframe\n",
    "    \"\"\"\n",
    "    reading_list = defaultdict(list)\n",
    "    top_n = get_top_n(predictions, n=10)\n",
    "    for n in top_n[userid]:\n",
    "        book, rating = n\n",
    "        title = books_users_ratings.loc[books_users_ratings.unique_isbn == book].book_title.unique()[0]\n",
    "        reading_list[title] = rating\n",
    "    return reading_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'The Amazing Adventures of Kavalier &amp; Clay': 7.400026743538274,\n",
       "             'The Book of Illusions: A Novel': 7.007931043368879,\n",
       "             \"CORELLI'S MANDOLIN : A Novel\": 6.331719735947438,\n",
       "             'The Last Time They Met : A Novel': 6.320274567617097})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reading_list(111637, test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
